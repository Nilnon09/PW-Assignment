{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f46cfc7",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e5f2c",
   "metadata": {},
   "source": [
    "Web Scraping is an automated method used to extract large amounts of data from websites. It allows programmers to collect content and data from web pages quickly and efficiently without needing to copy-paste manually. Web Scraping is used to collect real-time or bulk data for analysis, research, or automation purposes.\n",
    "Three common areas where Web Scraping is used include:\n",
    "\n",
    "1.E-commerce: To monitor product prices, availability, and competitor analysis.\n",
    "\n",
    "2.Job Portals: To gather job listings and analyze trends in hiring.\n",
    "\n",
    "3.News and Social Media: For sentiment analysis, content aggregation, and tracking trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17937071",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf37629",
   "metadata": {},
   "source": [
    "There are several methods for web scraping:\n",
    "\n",
    "Manual Scraping: Copying and pasting data manually (used for very small data).\n",
    "\n",
    "Using APIs: If a website provides a public API, data can be fetched in a structured format like JSON or XML.\n",
    "\n",
    "HTML Parsing: Libraries like BeautifulSoup or lxml parse the HTML content to extract data.\n",
    "\n",
    "Web Crawlers: Automated bots that systematically browse and extract data from websites.\n",
    "\n",
    "Selenium or Browser Automation: Used to scrape data from websites that rely heavily on JavaScript for rendering content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158256a",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae623f51",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for parsing HTML and XML documents. It creates a parse tree from page source codes that makes it easier to extract data from HTML tags. It is widely used in web scraping tasks because of its simple API and powerful methods to navigate, search, and modify the parse tree, making data extraction very convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d839c3",
   "metadata": {},
   "source": [
    "Q4. Why is Flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448afab6",
   "metadata": {},
   "source": [
    "Flask is used in a web scraping project to create a web-based interface or API that interacts with the scraping code. Instead of running the scraper in a terminal or script, Flask allows the user to trigger scraping via a web browser, input parameters (like a product name or URL), and display the scraped results on a webpage. It makes the project user-friendly and deployable, allowing multiple users to access scraping functionality remotely via the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc032640",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19c6bb",
   "metadata": {},
   "source": [
    "In this project, AWS services are used to deploy and manage the scraping application effectively.\n",
    "The common AWS services include:\n",
    "\n",
    "EC2 (Elastic Compute Cloud): This is used to host and run the Flask web scraping application on a virtual server. It provides scalable computing power.\n",
    "\n",
    "S3 (Simple Storage Service): Used to store scraped data, logs, or files generated during the scraping process securely.\n",
    "\n",
    "IAM (Identity and Access Management): Manages access permissions for the AWS services, ensuring security and control.\n",
    "\n",
    "Route 53: Helps in routing traffic to the web scraping application using domain names.\n",
    "\n",
    "CloudWatch (optional): Used to monitor the applicationâ€™s performance and log scraping activities for troubleshooting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865d246",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
