{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared (R²) measures how well the regression model explains the variability of the dependent variable. It ranges from 0 to 1.\n",
    "\n",
    "# Formula:\n",
    "# R² = 1 - (SSR / SST)\n",
    "# Where:\n",
    "\n",
    "# SSR = Sum of Squared Residuals\n",
    "\n",
    "# SST = Total Sum of Squares\n",
    "\n",
    "# Interpretation:\n",
    "\n",
    "# R² = 1: Perfect fit\n",
    "\n",
    "# R² = 0: Model explains none of the variance\n",
    "# A higher R² indicates a better model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted R-squared modifies the R² value by adjusting for the number of predictors in the model. It accounts for the possibility of overfitting when more variables are added.\n",
    "\n",
    "# Formula:\n",
    "# Adjusted R² = 1 - [(1 - R²) * (n - 1) / (n - p - 1)]\n",
    "# Where:\n",
    "\n",
    "# n = number of observations\n",
    "\n",
    "# p = number of predictors\n",
    "\n",
    "# Difference:\n",
    "# Regular R² always increases when a new variable is added, even if it’s not useful. Adjusted R² only increases if the new variable improves the model more than expected by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. When is it more appropriate to use adjusted R-squared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use adjusted R² when:\n",
    "\n",
    "# You are comparing models with different numbers of predictors.\n",
    "\n",
    "# You want to penalize the addition of irrelevant features. It provides a more reliable measure of model quality in multiple regression settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "calculated, and what do they represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are error metrics used to evaluate regression models:\n",
    "\n",
    "# MSE (Mean Squared Error):\n",
    "# MSE = (1/n) * Σ(actual - predicted)²\n",
    "# Measures average squared difference. Penalizes large errors.\n",
    "\n",
    "# RMSE (Root Mean Squared Error):\n",
    "# RMSE = √MSE\n",
    "# Same as MSE but in the same unit as the target variable.\n",
    "\n",
    "# MAE (Mean Absolute Error):\n",
    "# MAE = (1/n) * Σ|actual - predicted|\n",
    "# Measures average absolute error. Less sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE:\n",
    "\n",
    "# + Easy to interpret, not sensitive to outliers.\n",
    "\n",
    "# – Doesn't penalize large errors as much.\n",
    "\n",
    "# MSE:\n",
    "\n",
    "# + Penalizes large errors, good for highlighting big mistakes.\n",
    "\n",
    "# – Not in the same unit as the target variable.\n",
    "\n",
    "# RMSE:\n",
    "\n",
    "# + Penalizes large errors, same unit as target.\n",
    "\n",
    "# – More affected by outliers.\n",
    "\n",
    "# Use RMSE/MSE when large errors are worse than small ones. Use MAE when consistent performance is more important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "it more appropriate to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso (L1 Regularization):\n",
    "# Adds a penalty equal to the absolute value of the coefficients.\n",
    "# Cost Function:\n",
    "# Loss + λ * Σ|β|\n",
    "\n",
    "# Ridge (L2 Regularization):\n",
    "# Adds a penalty equal to the square of the coefficients.\n",
    "# Cost Function:\n",
    "# Loss + λ * Σβ²\n",
    "\n",
    "# Difference:\n",
    "\n",
    "# Lasso can shrink some coefficients to zero, performing feature selection.\n",
    "\n",
    "# Ridge shrinks coefficients but doesn’t make them zero.\n",
    "\n",
    "# Use Lasso when you expect only a few important variables and want feature selection.\n",
    "# Use Ridge when all variables may contribute and multicollinearity exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "example to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization penalizes large coefficients, simplifying the model. This reduces variance and prevents the model from fitting noise in the training data.\n",
    "\n",
    "# Example:\n",
    "# If a linear model overfits by assigning large weights to some variables, Lasso or Ridge will shrink those weights, making the model more generalizable on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "choice for regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitations:\n",
    "\n",
    "# May underfit if λ (penalty strength) is too high.\n",
    "\n",
    "# Doesn’t handle complex nonlinear relationships well.\n",
    "\n",
    "# Lasso struggles when features are highly correlated.\n",
    "\n",
    "# Still assumes linearity, normality, and homoscedasticity.\n",
    "\n",
    "# In nonlinear problems or when interpretability isn't critical, models like decision trees, random forests, or neural networks might be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "performer, and why? Are there any limitations to your choice of metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It depends:\n",
    "\n",
    "# If large errors are more harmful, RMSE is more relevant → Model A is worse.\n",
    "\n",
    "# If consistent performance is preferred, MAE is more relevant → Model B is better.\n",
    "\n",
    "# Limitation:\n",
    "\n",
    "# MAE and RMSE can't be directly compared unless on the same model.\n",
    "\n",
    "# They capture different aspects of error. Ideally, evaluate both metrics on the same model and compare accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "regulariz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would:\n",
    "\n",
    "# Compare evaluation metrics (RMSE, MAE, R²) on validation/test data.\n",
    "\n",
    "# Check coefficient sparsity (Lasso) vs shrinkage (Ridge).\n",
    "\n",
    "# Use cross-validation to select the regularization type and strength (λ).\n",
    "\n",
    "# Analyze feature importance: Lasso helps with interpretation by eliminating irrelevant features.\n",
    "\n",
    "# Ultimately, choose the model that gives the best trade-off between performance and interpretability for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
